{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOK2MzCkJRS3/0qxXqGsYsm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiachoi2001/ToBigs20/blob/main/Week1_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Library 와 Framework 의 차이 간단하게 서술하기. (100자 내외)\n",
        "\n",
        "Library는 특정 기능을 가진 함수, 클래스, 모듈로 이루어져 사용자가 가져와 쓸 수 있게 도와준다. Framework는 조금 더 고급 툴로 해당 프로젝트의 전체적인 구조와 아키텍쳐를 제공한다. 둘 중 하나가 더 우위에 있지는 않지만 framework는 프로젝트의 전체적인 흐름을 관장하는 반면 library는 특정 기능이 필요할 때 빌려와서 쓰기 떄문에 전체적인 흐름에는 영향을 적게 미친다."
      ],
      "metadata": {
        "id": "PWbg2TQ5S_av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하기. (200자 내외)\n",
        "\n",
        "머신러닝은 딥러닝을 포함하는 개념이다. 다르게 말하면 머신러닝의 세부 분야 중 딥러닝이 있는 것이다. 이 두 개념의 가장 큰 차이는 머신러닝은 사람이 특징을 추출하고 분류하는 과정에서 개입을 하는데 딥러닝은 인공신경망의 구축을 통해 스스로 학습한다는 점이다. 사람의 개입이 적고 다량의 데이터를 학습할 수 있다는 점에서 딥러닝은 빅데이터에 적합한 기술이라고 할 수 있다."
      ],
      "metadata": {
        "id": "Nivh_tVETBDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 주석으로 설명하기"
      ],
      "metadata": {
        "id": "26WthiAaVXrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Example"
      ],
      "metadata": {
        "id": "02_c4R5HUEM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### matplotlib 한글 폰트 깨짐 방지\n",
        "### 이 셀 실행시키고 런타임->런타임 다시 시작 한 다음에\n",
        "### 이 셀은 건너뛰고 아래부터 실행 시키면 됨.\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "id": "6oMohjBKWQ0O",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 드라이브 mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FacznXw1QzQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNVIPO2MQsVv"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager, rc\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AI/bundang.csv\")\n",
        "df = df.drop(columns=['시군구','단지명','건축년도'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uEH04h4vQwuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NaN값 개수\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "ti1k6F9-Qwwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 거래금액 히스토그램\n",
        "plt.hist(df['거래금액'],bins=100)"
      ],
      "metadata": {
        "id": "gekeGukSQwzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log값을 취해서 히스토그램\n",
        "df['거래금액_log'] = np.log(df['거래금액']+1)\n",
        "df = df.drop(columns=['거래금액'])\n",
        "plt.hist(df['거래금액_log'],bins=100)"
      ],
      "metadata": {
        "id": "feJ3CrxPQw15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런 모듈 가져오기\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# 타깃(Y)과 인풋(X) 설정\n",
        "Y = df['거래금액_log'].values\n",
        "Y = Y.astype('float32')\n",
        "X = df.drop(columns=['거래금액_log'])\n",
        "X = X.astype('float32')\n",
        "\n",
        "# 데이터셋을 학습 데이터와 테스트 데이터로 나눔\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=42)\n",
        "\n",
        "# RandomForestRegressor 모델 생성\n",
        "RF_model = RandomForestRegressor(n_estimators=2000, random_state=42)\n",
        "# 학습\n",
        "RF_model.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "eB8-PjXQQw4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "Train_Prediction = (RF_model.predict(X_train))\n",
        "Test_Prediction = (RF_model.predict(X_test))\n",
        "\n",
        "# 학습 데이터와 테스트 데이터 각각 회귀 모델 성능 평가 지표인 MAE와 MAPE 구하기\n",
        "RF_Train_MAE = round(np.mean(np.abs(Y_train-Train_Prediction)),3)\n",
        "RF_Train_MAPE = round((np.mean(np.abs((Y_train-Train_Prediction)/(Y_train)))*100),3)\n",
        "\n",
        "RF_Test_MAE = round(np.mean(np.abs(Y_test-Test_Prediction)),3)\n",
        "RF_Test_MAPE = round((np.mean(np.abs((Y_test-Test_Prediction)/(Y_test)))*100),3)\n",
        "\n",
        "print(\"Mean Absolute Error for Train Set is : {:.3f}\".format(RF_Train_MAE))\n",
        "print(\"Mean Absolute Percent Error for Train Set is : {:.3f} %\".format(RF_Train_MAPE))\n",
        "print(\"Mean Absolute Error for Test Set is : {:.3f}\".format(RF_Test_MAE))\n",
        "print(\"Mean Absolute Percent Error for Test Set is : {:.3f} %\".format(RF_Test_MAPE))"
      ],
      "metadata": {
        "id": "hg0XB_PpQw7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log 값 취한 것을 다시 되돌림 (실제 / 예측값)\n",
        "Original_Predictions = (np.round(np.exp(Test_Prediction+1),-2)).astype(int)\n",
        "print(Original_Predictions[:10])\n",
        "Original_Values = (np.round(np.exp(Y_test+1),-2)).astype(int)\n",
        "print(Original_Values[:10])\n",
        "data = {'Original':  Original_Values,'Prediction': Original_Predictions}\n",
        "final = pd.DataFrame(data)\n",
        "final"
      ],
      "metadata": {
        "id": "rxmAwJRhQxAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RF 모델 feature importances 불러와서 bar차트로 표\n",
        "sorted_idx = RF_model.feature_importances_.argsort()\n",
        "plt.barh(X.columns[sorted_idx], RF_model.feature_importances_[sorted_idx])\n",
        "plt.xlabel(\"Random Forest Feature Importance\")"
      ],
      "metadata": {
        "id": "0q6OKrUwQxDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "UnuZmzfLSApu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost를 사용해서 같은 것을 반복\n",
        "import xgboost\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 나누\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=41)\n",
        "XGB_model = xgboost.XGBRegressor(n_estimators=2000, random_state=41)\n",
        "\n",
        "# 학습\n",
        "XGB_model.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "FJ7-4rclQxGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "Train_Prediction = (XGB_model.predict(X_train))\n",
        "Test_Prediction = (XGB_model.predict(X_test))\n",
        "\n",
        "# MAE와 MAPE 구하기\n",
        "XGB_Train_MAE = round(np.mean(np.abs(Y_train-Train_Prediction)),3)\n",
        "XGB_Train_MAPE = round((np.mean(np.abs((Y_train-Train_Prediction)/(Y_train)))*100),3)\n",
        "\n",
        "XGB_Test_MAE = round(np.mean(np.abs(Y_test-Test_Prediction)),3)\n",
        "XGB_Test_MAPE = round((np.mean(np.abs((Y_test-Test_Prediction)/(Y_test)))*100),3)\n",
        "\n",
        "print(\"Mean Absolute Error for Train Set is : {:.3f}\".format(XGB_Train_MAE))\n",
        "print(\"Mean Absolute Percent Error for Train Set is : {:.3f} %\".format(XGB_Train_MAPE))\n",
        "print(\"Mean Absolute Error for Test Set is : {:.3f}\".format(XGB_Test_MAE))\n",
        "print(\"Mean Absolute Percent Error for Test Set is : {:.3f} %\".format(XGB_Test_MAPE))"
      ],
      "metadata": {
        "id": "Ila5zFZgQxIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature importance 표시하기\n",
        "xgboost.plot_importance(XGB_model)"
      ],
      "metadata": {
        "id": "LsMb89cbS2Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCGAN Example"
      ],
      "metadata": {
        "id": "te4WY7djT5ZB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM3Df-VsRaMk"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 import\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 활용이 가능하면 사용, 불가능하면 CPU 사용\n",
        "GPU_NUM = 0\n",
        "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available else 'cpu')\n",
        "torch.cuda.set_device(device)\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "j7BiiRncRdlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN 모델의 discriminator 클래스 생성\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,channels_img,features_d):\n",
        "        # 부모 클래스 상속\n",
        "        super(Discriminator,self).__init__()\n",
        "        # NN layer 설정\n",
        "        self.disc=nn.Sequential(\n",
        "            nn.Conv2d(channels_img,features_d,kernel_size=4,stride=2,padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            self._block(features_d,features_d*2,4,2,1),\n",
        "            self._block(features_d*2,features_d*4,4,2,1),\n",
        "            self._block(features_d*4,features_d*8,4,2,1),\n",
        "            nn.Conv2d(features_d*8,1,kernel_size=4,stride=2,padding=1),\n",
        "            nn.Sigmoid(), )\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size,stride,padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False,),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2),)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.disc(x)\n",
        "\n",
        "# GAN 모델의 generator 클래스 생성\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,z_dim,channels_img,features_g):\n",
        "        super(Generator,self).__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            self._block(z_dim,features_g*16,4,1,0),\n",
        "            self._block(features_g*16,features_g*8,4,2,1),\n",
        "            self._block(features_g*8,features_g*4,4,2,1),\n",
        "            self._block(features_g*4,features_g*2,4,2,1),\n",
        "            nn.ConvTranspose2d(\n",
        "                features_g*2, channels_img,kernel_size=4,stride=2,padding=1,\n",
        "            ),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "    def _block(self,in_channels,out_channels,kernel_size,stride,padding):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride,padding,bias=False,),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.gen(x)\n",
        "\n",
        "# 모델 가중치 초기화\n",
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m,(nn.Conv2d,nn.ConvTranspose2d,nn.BatchNorm2d)):\n",
        "            nn.init.normal_(m.weight.data,0.0,0.02)"
      ],
      "metadata": {
        "id": "tBRLLOIFRdpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 display 함수\n",
        "def show_image(dataset, times):\n",
        "    for i in range(times):\n",
        "        t = random.randint(1,len(dataset))\n",
        "        temp_image = dataset.data[t]\n",
        "        temp_image = np.array(temp_image, dtype='float')\n",
        "        pixels = temp_image.reshape((28, 28))\n",
        "        plt.figure(figsize=(2,2))\n",
        "        plt.imshow(pixels, cmap='gray')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "hiCrT2lYRdsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 불러오기\n",
        "dataset = datasets.MNIST(root=\"dataset/\",train=True,download=True)\n",
        "\n",
        "# 이미지 3개 display\n",
        "show_image(dataset,3)"
      ],
      "metadata": {
        "id": "kxuu356xRdwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter 설정\n",
        "LEARNING_RATE = 3e-4\n",
        "BATCH_SIZE = 128\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS_IMG = 1\n",
        "Z_DIM = 100\n",
        "NUM_EPOCHS=40\n",
        "FEATURES_DISC=64\n",
        "FEATURES_GEN=64"
      ],
      "metadata": {
        "id": "trV6sXIbRdzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 설정\n",
        "dataset = datasets.MNIST(root='dataset/',download=True,train=True,transform=transforms)\n",
        "\n",
        "# 타킷 설정\n",
        "SPLIT={0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[]}\n",
        "for i in range(len(dataset.targets)):\n",
        "    SPLIT[dataset.targets[i].item()].append(i)\n",
        "\n",
        "# 데이터 split (타킷)\n",
        "def split(data,target):\n",
        "    data.data = data.data[SPLIT[target]]\n",
        "    data.targets = data.targets[SPLIT[target]]\n",
        "\n",
        "# transform pipline 생성\n",
        "Transforms = transforms.Compose([\n",
        "                                 transforms.Resize(IMAGE_SIZE),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize([0.5 for _ in range(CHANNELS_IMG)],[0.5 for _ in range(CHANNELS_IMG)]),\n",
        "])\n",
        "\n",
        "# transform 적용\n",
        "one_data = datasets.MNIST(root=\"dataset/\",train=True,transform=Transforms,download=True)\n",
        "print(one_data.targets)\n",
        "print(len(one_data))\n",
        "\n",
        "\n",
        "### 이 한 줄을 주석처리시키면\n",
        "### 60000개 데이터 전부 사용해서 학습을 시킬 수 있다.\n",
        "# split(one_data,3)\n",
        "\n",
        "# 이미지 display\n",
        "show_image(one_data,3)\n",
        "print(one_data.targets)\n",
        "print(len(one_data))"
      ],
      "metadata": {
        "id": "FZmavoIJRd2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 생성\n",
        "One_Data_Loader=DataLoader(one_data,batch_size=BATCH_SIZE, shuffle=True)\n",
        "# generator와 discriminator 생성 (device로 배정)\n",
        "One_gen = Generator(Z_DIM, CHANNELS_IMG , FEATURES_GEN).to(device)\n",
        "One_disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n",
        "# weight 초기화\n",
        "initialize_weights(One_gen)\n",
        "initialize_weights(One_disc)\n",
        "# optimizer 설정\n",
        "opt_gen = optim.Adam(One_gen.parameters(), lr = LEARNING_RATE, betas=(0.5,0.999))\n",
        "opt_disc = optim.Adam(One_disc.parameters(), lr = LEARNING_RATE, betas=(0.5,0.999))\n",
        "# loss 함수 설정\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# generator와 discriminator 학습\n",
        "One_gen.train()\n",
        "One_disc.train()\n",
        "Start_Time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\t\t### 이 아래의 for 문 한 줄에서 y 값을 사용하고 있지 않음을 알 수 있습니다.\n",
        "    for batch_idx, (real,_) in enumerate(One_Data_Loader):\n",
        "\n",
        "        real = real.to(device)\n",
        "        noise = torch.randn((BATCH_SIZE,Z_DIM,1,1)).to(device)\n",
        "        fake = One_gen(noise)\n",
        "\n",
        "        disc_real = One_disc(real).reshape(-1)\n",
        "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "\n",
        "        disc_fake = One_disc(fake).reshape(-1)\n",
        "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "\n",
        "        loss_disc = (loss_disc_real+loss_disc_fake)/2\n",
        "\n",
        "        One_disc.zero_grad()\n",
        "        loss_disc.backward(retain_graph=True)\n",
        "        opt_disc.step()\n",
        "\n",
        "        output = One_disc(fake).reshape(-1)\n",
        "        loss_gen = criterion(output,torch.ones_like(output))\n",
        "        One_gen.zero_grad()\n",
        "        loss_gen.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "    # generator로 생성한 이미지 show\n",
        "    if (epoch+1)%(max(1,NUM_EPOCHS//5))==0:\n",
        "        Z = torch.randn(100,100,1,1).to(device)\n",
        "        out_gen = One_gen(Z)\n",
        "        Image_Loader=DataLoader(out_gen,batch_size=64, shuffle=True)\n",
        "        real_batch = next(iter(Image_Loader))\n",
        "        plt.figure(figsize=(8,8))\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"Fake Images in Epoch {}\".format(epoch+1))\n",
        "        plt.imshow(np.transpose(vutils.make_grid(real_batch.to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "        plt.show()\n",
        "\n",
        "    # 학습 시간 프린트\n",
        "    print(\"Progress : [ {} / {} ], Time : {:.3f} (min) \".format(epoch+1,NUM_EPOCHS,(time.time()-Start_Time)/60) )"
      ],
      "metadata": {
        "id": "Y7_KyewsRd5a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}